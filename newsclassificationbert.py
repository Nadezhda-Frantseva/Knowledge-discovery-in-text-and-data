# -*- coding: utf-8 -*-
"""NewsClassificationBert.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1MGP1OPWxr7vPqHwfETktCJGMBj2dd6rp
"""

import tensorflow as tf
from transformers import BertTokenizer, TFBertForSequenceClassification
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.pipeline import make_pipeline
from sklearn.svm import SVC
from sklearn.naive_bayes import MultinomialNB
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report
from sklearn.model_selection import train_test_split

from google.colab import drive
drive.mount('/content/drive')

import tensorflow as tf
physical_devices = tf.config.list_physical_devices('GPU')
physical_devices

import pandas as pd
import glob

# Път до папката, където се намират CSV файловете
path = '/content/sample_data/data'

# Списък с всички CSV файлове в папката
all_files = glob.glob(path + "/*.csv")

# Зареждане на всички CSV файлове в списък от DataFrames
dfs = [pd.read_csv(file) for file in all_files]

# Сливане на всички DataFrames в един
merged_df = pd.concat(dfs, ignore_index=True)

# Записване на резултата в нов CSV файл
merged_df.to_csv('/content/sample_data/merged_file.csv', index=False)

print("Обединените данни са запазени в merged_file.csv")

import pandas as pd

# Път до файла със данните
file_path = '/content/sample_data/merged_file.csv'

# Зареждане на данните
data = pd.read_csv(file_path)

# Извличане на текстове и категории
texts = data['news_article'].tolist()
labels = data['news_category'].tolist()

# Преобразуване на категориите в числови етикети
category_to_label = {category: index for index, category in enumerate(data['news_category'].unique())}
labels = [category_to_label[label] for label in labels]

print(data.head())

print(labels)

# Разделяне на данните на обучителен и тестов набор
train_texts, test_texts, train_labels, test_labels = train_test_split(texts, labels, test_size=0.2, random_state=42)

# Предварителна обработка на данните с TF-IDF
vectorizer = TfidfVectorizer(max_features=10000)
train_vectors = vectorizer.fit_transform(train_texts)
test_vectors = vectorizer.transform(test_texts)

!nvidia-smi

# Зареждане на предварително обучен BERT модел за английски език и токенизатор
tokenizer = BertTokenizer.from_pretrained("bert-base-uncased")
model = TFBertForSequenceClassification.from_pretrained("bert-base-uncased", num_labels=7)

# Кодиране на текстовете и подготовка на данните за обучение
train_encodings = tokenizer(train_texts, truncation=True, padding=True)
test_encodings = tokenizer(test_texts, truncation=True, padding=True)

# Преобразуване на етикетите в тензори
train_labels = tf.convert_to_tensor(train_labels, dtype=tf.int32)
test_labels = tf.convert_to_tensor(test_labels, dtype=tf.int32)

train_dataset = tf.data.Dataset.from_tensor_slices((
    dict(train_encodings),
    train_labels
)).shuffle(100).batch(16)

test_dataset = tf.data.Dataset.from_tensor_slices((
    dict(test_encodings),
    test_labels
)).batch(16)

# Конфигуриране на модела за обучение
optimizer = tf.keras.optimizers.Adam(learning_rate=3e-5)
# Проверете дали модела връща не-None стойности
model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])

# Обучение на модела
model.fit(train_dataset, epochs=3, validation_data=test_dataset)

# Оценка на модела
loss, accuracy = model.evaluate(test_dataset)
print(f'BERT accuracy: {accuracy}')

# Получаване на предсказания от BERT модела
bert_pred = model.predict(test_dataset)
bert_pred_labels = tf.argmax(bert_pred.logits, axis=1)

# Преобразуване на тестовите етикети в numpy масив, ако не са вече
test_labels_array = test_labels.numpy() if tf.is_tensor(test_labels) else test_labels

# Изчисляване на метриките
bert_f1 = f1_score(test_labels_array, bert_pred_labels, average='weighted')
bert_precision = precision_score(test_labels_array, bert_pred_labels, average='weighted')
bert_recall = recall_score(test_labels_array, bert_pred_labels, average='weighted')

print(f'BERT F1 Score: {bert_f1}')
print(f'BERT Precision: {bert_precision}')
print(f'BERT Recall: {bert_recall}')
print(classification_report(test_labels_array, bert_pred_labels))

from transformers import RobertaTokenizer, TFRobertaForSequenceClassification

tokenizer = RobertaTokenizer.from_pretrained("roberta-base")
model = TFRobertaForSequenceClassification.from_pretrained("roberta-base", num_labels=7)

# Кодиране на текстовете и подготовка на данните за обучение
train_encodings = tokenizer(train_texts, truncation=True, padding=True)
test_encodings = tokenizer(test_texts, truncation=True, padding=True)

# Преобразуване на етикетите в тензори
train_labels = tf.convert_to_tensor(train_labels, dtype=tf.int32)
test_labels = tf.convert_to_tensor(test_labels, dtype=tf.int32)

train_dataset = tf.data.Dataset.from_tensor_slices((
    dict(train_encodings),
    train_labels
)).shuffle(100).batch(16)

test_dataset = tf.data.Dataset.from_tensor_slices((
    dict(test_encodings),
    test_labels
)).batch(16)

# Конфигуриране на модела за обучение
optimizer = tf.keras.optimizers.Adam(learning_rate=1e-5)
model.compile(optimizer=optimizer, loss=model.compute_loss, metrics=['accuracy'])

# Ensure the model runs on GPU if available
if tf.config.list_physical_devices('GPU'):
    print("Using GPU")
else:
    print("Using CPU")

# Train the model
with tf.device('/GPU:0'):
    model.fit(train_dataset, epochs=3, validation_data=test_dataset)

# Evaluate the model
with tf.device('/GPU:0'):
    loss, accuracy = model.evaluate(test_dataset)
print(f'roBERTa accuracy: {accuracy}')

from transformers import DistilBertTokenizer, TFDistilBertForSequenceClassification
import tensorflow as tf
from sklearn.model_selection import train_test_split
from sklearn.metrics import f1_score, precision_score, recall_score, classification_report
import pandas as pd

# Зареждане на данните
file_path = '/content/sample_data/merged_file.csv'
data = pd.read_csv(file_path)

# Извличане на текстове и категории
texts = data['news_article'].tolist()
labels = data['news_category'].tolist()

# Преобразуване на категориите в числови етикети
category_to_label = {category: index for index, category in enumerate(data['news_category'].unique())}
labels = [category_to_label[label] for label in labels]

# Разделяне на данните на обучителен и тестов набор
train_texts, test_texts, train_labels, test_labels = train_test_split(texts, labels, test_size=0.2, random_state=42)

# Зареждане на токенизатора и модела
tokenizer = DistilBertTokenizer.from_pretrained("distilbert-base-uncased")
model = TFDistilBertForSequenceClassification.from_pretrained("distilbert-base-uncased", num_labels=len(category_to_label))

# Подготовка на данните
train_encodings = tokenizer(train_texts, truncation=True, padding=True, max_length=128)
test_encodings = tokenizer(test_texts, truncation=True, padding=True, max_length=128)

# Преобразуване на етикетите в тензори
train_labels = tf.convert_to_tensor(train_labels, dtype=tf.int32)
test_labels = tf.convert_to_tensor(test_labels, dtype=tf.int32)

train_dataset = tf.data.Dataset.from_tensor_slices((
    dict(train_encodings),
    train_labels
)).shuffle(100).batch(16)

test_dataset = tf.data.Dataset.from_tensor_slices((
    dict(test_encodings),
    test_labels
)).batch(16)

# Конфигуриране на модела за обучение
optimizer = tf.keras.optimizers.Adam(learning_rate=3e-5)
model.compile(optimizer=optimizer, loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])

# Обучение на модела
model.fit(train_dataset, epochs=5, validation_data=test_dataset)

# Оценка на модела
loss, accuracy = model.evaluate(test_dataset)
print(f'DistilBERT accuracy: {accuracy}')

# Изчисляване на метриките
distilbert_pred = model.predict(test_dataset)
distilbert_pred_labels = tf.argmax(distilbert_pred.logits, axis=1).numpy()

# Преобразуване на тестовите етикети в numpy масив, ако не са вече
test_labels_array = test_labels.numpy() if tf.is_tensor(test_labels) else test_labels

distilbert_f1 = f1_score(test_labels_array, distilbert_pred_labels, average='weighted')
distilbert_precision = precision_score(test_labels_array, distilbert_pred_labels, average='weighted')
distilbert_recall = recall_score(test_labels_array, distilbert_pred_labels, average='weighted')

print(f'DistilBERT F1 Score: {distilbert_f1}')
print(f'DistilBERT Precision: {distilbert_precision}')
print(f'DistilBERT Recall: {distilbert_recall}')
print(classification_report(test_labels_array, distilbert_pred_labels))